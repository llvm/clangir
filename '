// RUN: %clang_cc1 -std=c++17 -triple x86_64-unknown-linux-gnu -fclangir -emit-cir %s -o %t.cir
// RUN: FileCheck --input-file=%t.cir %s
// RUN: %clang_cc1 -std=c++17 -triple x86_64-unknown-linux-gnu -fclangir -emit-llvm %s -o %t.ll
// cat %t.ll
// RUN: FileCheck --check-prefix=LLVM --input-file=%t.ll %s

// Available on resource dir.
#include <stdatomic.h>

typedef struct _a {
  _Atomic(int) d;
} at;

void m() { at y; }

signed char sc;
unsigned char uc;
signed short ss;
unsigned short us;
signed int si;
unsigned int ui;
signed long long sll;
unsigned long long ull;

// CHECK-LABEL: @test_op_and_fetch
// LLVM-LABEL: @test_op_and_fetch
extern "C" void test_op_and_fetch (void)
{

  // CHECK: [[VAL0:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !s8i
  // CHECK: [[RES0:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!s8i>, [[VAL0]] : !s8i, seq_cst) fetch_first : !s8i
  // CHECK: [[INTERM0:%.*]] = cir.binop(and, [[RES0]], [[VAL0]]) : !s8i
  // CHECK: [[RET0:%.*]] =  cir.unary(not, [[INTERM0]]) : !s8i, !s8i
  // LLVM:  [[VAL0:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[RES0:%.*]] = atomicrmw nand ptr @sc, i8 [[VAL0]] seq_cst, align 1
  // LLVM:  [[INTERM0:%.*]] = and i8 [[RES0]], [[VAL0]]
  // LLVM:  [[RET0:%.*]] = xor i8 [[INTERM0]], -1
  // LLVM:  store i8 [[RET0]], ptr @sc, align 1
  sc = __sync_nand_and_fetch(&sc, uc); 

  // CHECK: [[RES1:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!u8i>, [[VAL1:%.*]] : !u8i, seq_cst) fetch_first : !u8i
  // CHECK: [[INTERM1:%.*]] = cir.binop(and, [[RES1]], [[VAL1]]) : !u8i
  // CHECK: [[RET1:%.*]] = cir.unary(not, [[INTERM1]]) : !u8i, !u8i
  // LLVM:  [[VAL1:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[RES1:%.*]] = atomicrmw nand ptr @uc, i8 [[VAL1]] seq_cst, align 1
  // LLVM:  [[INTERM1:%.*]] = and i8 [[RES1]], [[VAL1]]
  // LLVM:  [[RET1:%.*]] = xor i8 [[INTERM1]], -1
  // LLVM:  store i8 [[RET1]], ptr @sc, align 1
  uc = __sync_nand_and_fetch (&uc, uc); 
  
  // CHECK: [[VAL2:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !s16i
  // CHECK: [[RES2:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!s16i>, [[VAL2]] : !s16i, seq_cst) fetch_first : !s16i
  // CHECK: [[INTERM2:%.*]] = cir.binop(and, [[RES2]], [[VAL2]]) : !s16i
  // CHECK: [[RET2:%.*]] =  cir.unary(not, [[INTERM2]]) : !s16i, !s16i
  // LLVM:  [[VAL2:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[CONV2:%.*]] = zext i8 [[VAL2]] to i16
  // LLVM:  [[RES2:%.*]] = atomicrmw nand ptr @ss, i16 [[CONV2]] seq_cst, align 1
  // LLVM:  [[INTERM2:%.*]] = and i16 [[RES2]], [[CONV2]]
  // LLVM:  [[RET2:%.*]] = xor i16 [[INTERM2]], -1
  // LLVM:  store i16 [[RET2]], ptr @sc, align 1
  ss = __sync_nand_and_fetch (&ss, uc); 

  // CHECK: [[VAL3:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !u16i
  // CHECK: [[RES3:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!u16i>, [[VAL3]] : !u16i, seq_cst) fetch_first : !u16i
  // CHECK: [[INTERM3:%.*]] = cir.binop(and, [[RES3]], [[VAL3]]) : !u16i
  // CHECK: [[RET3:%.*]] =  cir.unary(not, [[INTERM3]]) : !u16i, !u16i
  // LLVM:  [[VAL3:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[CONV3:%.*]] = zext i8 [[VAL3]] to i16
  // LLVM:  [[RES3:%.*]] = atomicrmw nand ptr @us, i16 [[VAL3]] seq_cst, align 1
  // LLVM:  [[INTERM3:%.*]] = and i16 [[RES3]], [[VAL3]]
  // LLVM:  [[RET3:%.*]] = xor i16 [[INTERM3]], -1
  // LLVM:  store i16 [[RET3]], ptr @sc, align 1
  us = __sync_nand_and_fetch (&us, uc); 

  // CHECK: [[VAL4:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !s32i
  // CHECK: [[RES4:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!s32i>, [[VAL4]] : !s32i, seq_cst) fetch_first : !s32i
  // CHECK: [[INTERM4:%.*]] = cir.binop(and, [[RES4]], [[VAL4]]) : !s32i
  // CHECK: [[RET4:%.*]] =  cir.unary(not, [[INTERM4]]) : !s32i, !s32i
  // LLVM:  [[VAL4:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[CONV4:%.*]] = zext i8 [[VAL4]] to i32
  // LLVM:  [[RES4:%.*]] = atomicrmw nand ptr @si, i32 [[CONV4]] seq_cst, align 1
  // LLVM:  [[INTERM4:%.*]] = and i32 [[RES4]], [[VAL4]]
  // LLVM:  [[RET4:%.*]] = xor i32 [[INTERM4]], -1
  // LLVM:  store i32 [[RET4]], ptr @sc, align 1
  si = __sync_nand_and_fetch (&si, uc); 

  // CHECK: [[VAL5:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !u32i
  // CHECK: [[RES5:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!u32i>, [[VAL5]] : !u32i, seq_cst) fetch_first : !u32i
  // CHECK: [[INTERM5:%.*]] = cir.binop(and, [[RES5]], [[VAL5]]) : !u32i
  // CHECK: [[RET5:%.*]] =  cir.unary(not, [[INTERM5]]) : !u32i, !u32i
  // LLVM:  [[VAL5:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[CONV5:%.*]] = zext i8 [[VAL5]] to i32
  // LLVM:  [[RES5:%.*]] = atomicrmw nand ptr @ui, i32 [[CONV5]] seq_cst, align 1
  // LLVM:  [[INTERM5:%.*]] = and i32 [[RES5]], [[CONV5]]
  // LLVM:  [[RET5:%.*]] = xor i32 [[INTERM5]], -1
  // LLVM:  store i32 [[RET5]], ptr @sc, align 1
  ui = __sync_nand_and_fetch (&ui, uc); 

  // CHECK: [[VAL6:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !s64i
  // CHECK: [[RES6:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!s64i>, [[VAL6]] : !s64i, seq_cst) fetch_first : !s64i
  // CHECK: [[INTERM6:%.*]] = cir.binop(and, [[RES6]], [[VAL6]]) : !s64i
  // CHECK: [[RET6:%.*]] =  cir.unary(not, [[INTERM6]]) : !s64i, !s64i
  // LLVM:  [[VAL6:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[CONV6:%.*]] = zext i8 [[VAL6]] to i64
  // LLVM:  [[RES6:%.*]] = atomicrmw nand ptr @sll, i64 [[CONV6]] seq_cst, align 1
  // LLVM:  [[INTERM6:%.*]] = and i64 [[RES6]], [[CONV6]]
  // LLVM:  [[RET6:%.*]] = xor i64 [[INTERM6]], -1
  // LLVM:  store i64 [[RET6]], ptr @sc, align 1
  sll = __sync_nand_and_fetch (&sll, uc); 

  // CHECK: [[VAL7:%.*]] = cir.cast(integral, {{%.*}} : !u8i), !u64i
  // CHECK: [[RES7:%.*]] = cir.atomic.fetch(nand, {{%.*}} : !cir.ptr<!u64i>, [[VAL7]] : !u64i, seq_cst) fetch_first : !u64i
  // CHECK: [[INTERM7:%.*]] = cir.binop(and, [[RES7]], [[VAL7]]) : !u64i
  // CHECK: [[RET7:%.*]] =  cir.unary(not, [[INTERM7]]) : !u64i, !u64i
  // LLVM:  [[VAL7:%.*]] = load i8, ptr @uc, align 1
  // LLVM:  [[CONV7:%.*]] = zext i8 [[VAL7]] to i64
  // LLVM:  [[RES7:%.*]] = atomicrmw nand ptr @ull, i64 [[CONV7]] seq_cst, align 1
  // LLVM:  [[INTERM7:%.*]] = and i64 [[RES7]], [[CONV7]]
  // LLVM:  [[RET7:%.*]] = xor i64 [[INTERM7]], -1
  // LLVM:  store i64 [[RET7]], ptr @sc, align 1
  ull = __sync_nand_and_fetch (&ull, uc);

}
