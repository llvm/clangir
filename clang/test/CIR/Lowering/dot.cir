// RUN: cir-opt %s -cir-to-llvm --reconcile-unrealized-casts -o %t.mlir
// RUN: FileCheck --input-file=%t.mlir %s -check-prefix=MLIR

!s32i = !cir.int<s, 32>
module {
  cir.func @dot(%arg0: !cir.ptr<f64>, %arg1: !cir.ptr<f64>, %arg2: !s32i) -> f64 {
    %0 = cir.alloca !cir.ptr<f64>, cir.ptr <!cir.ptr<f64>>, ["a", init] {alignment = 8 : i64}
    %1 = cir.alloca !cir.ptr<f64>, cir.ptr <!cir.ptr<f64>>, ["b", init] {alignment = 8 : i64}
    %2 = cir.alloca !s32i, cir.ptr <!s32i>, ["size", init] {alignment = 4 : i64}
    %3 = cir.alloca f64, cir.ptr <f64>, ["__retval"] {alignment = 8 : i64}
    %4 = cir.alloca f64, cir.ptr <f64>, ["q", init] {alignment = 8 : i64}
    cir.store %arg0, %0 : !cir.ptr<f64>, cir.ptr <!cir.ptr<f64>>
    cir.store %arg1, %1 : !cir.ptr<f64>, cir.ptr <!cir.ptr<f64>>
    cir.store %arg2, %2 : !s32i, cir.ptr <!s32i>
    %5 = cir.const(0.000000e+00 : f64) : f64
    cir.store %5, %4 : f64, cir.ptr <f64>
    cir.scope {
      %8 = cir.alloca !s32i, cir.ptr <!s32i>, ["i", init] {alignment = 4 : i64}
      %9 = cir.const(#cir.int<0> : !s32i) : !s32i
      cir.store %9, %8 : !s32i, cir.ptr <!s32i>
      cir.for : cond {
        %10 = cir.load %8 : cir.ptr <!s32i>, !s32i
        %11 = cir.load %2 : cir.ptr <!s32i>, !s32i
        %12 = cir.cmp(lt, %10, %11) : !s32i, !s32i
        %13 = cir.cast(int_to_bool, %12 : !s32i), !cir.bool
        cir.condition(%13)
      } body {
        %10 = cir.load %0 : cir.ptr <!cir.ptr<f64>>, !cir.ptr<f64>
        %11 = cir.load %8 : cir.ptr <!s32i>, !s32i
        %12 = cir.ptr_stride(%10 : !cir.ptr<f64>, %11 : !s32i), !cir.ptr<f64>
        %13 = cir.load %12 : cir.ptr <f64>, f64
        %14 = cir.load %1 : cir.ptr <!cir.ptr<f64>>, !cir.ptr<f64>
        %15 = cir.load %8 : cir.ptr <!s32i>, !s32i
        %16 = cir.ptr_stride(%14 : !cir.ptr<f64>, %15 : !s32i), !cir.ptr<f64>
        %17 = cir.load %16 : cir.ptr <f64>, f64
        %18 = cir.binop(mul, %13, %17) : f64
        %19 = cir.load %4 : cir.ptr <f64>, f64
        %20 = cir.binop(add, %19, %18) : f64
        cir.store %20, %4 : f64, cir.ptr <f64>
        cir.yield
      } step {
        %10 = cir.load %8 : cir.ptr <!s32i>, !s32i
        %11 = cir.unary(inc, %10) : !s32i, !s32i
        cir.store %11, %8 : !s32i, cir.ptr <!s32i>
        cir.yield
      }
    }
    %6 = cir.load %4 : cir.ptr <f64>, f64
    cir.store %6, %3 : f64, cir.ptr <f64>
    %7 = cir.load %3 : cir.ptr <f64>, f64
    cir.return %7 : f64
  }
}

//      MLIR: module {
// MLIR-NEXT:   llvm.func @dot(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i32) -> f64
// MLIR-NEXT:     %0 = llvm.mlir.constant(1 : index) : i64
// MLIR-NEXT:     %1 = llvm.alloca %0 x !llvm.ptr {alignment = 8 : i64} : (i64) -> !llvm.ptr
// MLIR-NEXT:     %2 = llvm.mlir.constant(1 : index) : i64
// MLIR-NEXT:     %3 = llvm.alloca %2 x !llvm.ptr {alignment = 8 : i64} : (i64) -> !llvm.ptr
// MLIR-NEXT:     %4 = llvm.mlir.constant(1 : index) : i64
// MLIR-NEXT:     %5 = llvm.alloca %4 x i32 {alignment = 4 : i64} : (i64) -> !llvm.ptr
// MLIR-NEXT:     %6 = llvm.mlir.constant(1 : index) : i64
// MLIR-NEXT:     %7 = llvm.alloca %6 x f64 {alignment = 8 : i64} : (i64) -> !llvm.ptr
// MLIR-NEXT:     %8 = llvm.mlir.constant(1 : index) : i64
// MLIR-NEXT:     %9 = llvm.alloca %8 x f64 {alignment = 8 : i64} : (i64) -> !llvm.ptr
// MLIR-NEXT:     llvm.store %arg0, %1 : !llvm.ptr, !llvm.ptr
// MLIR-NEXT:     llvm.store %arg1, %3 : !llvm.ptr, !llvm.ptr
// MLIR-NEXT:     llvm.store %arg2, %5 : i32, !llvm.ptr
// MLIR-NEXT:     %10 = llvm.mlir.constant(0.000000e+00 : f64) : f64
// MLIR-NEXT:     llvm.store %10, %9 : f64, !llvm.ptr
// MLIR-NEXT:     llvm.br ^bb1
// MLIR-NEXT:   ^bb1:  // pred: ^bb0
// MLIR-NEXT:     %11 = llvm.mlir.constant(1 : index) : i64
// MLIR-NEXT:     %12 = llvm.alloca %11 x i32 {alignment = 4 : i64} : (i64) -> !llvm.ptr
// MLIR-NEXT:     %13 = llvm.mlir.constant(0 : i32) : i32
// MLIR-NEXT:     llvm.store %13, %12 : i32, !llvm.ptr
// MLIR-NEXT:     llvm.br ^bb2
// MLIR-NEXT:   ^bb2:  // 2 preds: ^bb1, ^bb4
// MLIR-NEXT:     %14 = llvm.load %12 : !llvm.ptr -> i32
// MLIR-NEXT:     %15 = llvm.load %5 : !llvm.ptr -> i32
// MLIR-NEXT:     %16 = llvm.icmp "slt" %14, %15 : i32
// MLIR-NEXT:     %17 = llvm.zext %16 : i1 to i32
// MLIR-NEXT:     %18 = llvm.mlir.constant(0 : i32) : i32
// MLIR-NEXT:     %19 = llvm.icmp "ne" %17, %18 : i32
// MLIR-NEXT:     %20 = llvm.zext %19 : i1 to i8
// MLIR-NEXT:     %21 = llvm.trunc %20 : i8 to i1
// MLIR-NEXT:     llvm.cond_br %21, ^bb3, ^bb5
// MLIR-NEXT:   ^bb3:  // pred: ^bb2
// MLIR-NEXT:     %22 = llvm.load %1 : !llvm.ptr -> !llvm.ptr
// MLIR-NEXT:     %23 = llvm.load %12 : !llvm.ptr -> i32
// MLIR-NEXT:     %24 = llvm.getelementptr %22[%23] : (!llvm.ptr, i32) -> !llvm.ptr, f64
// MLIR-NEXT:     %25 = llvm.load %24 : !llvm.ptr -> f64
// MLIR-NEXT:     %26 = llvm.load %3 : !llvm.ptr -> !llvm.ptr
// MLIR-NEXT:     %27 = llvm.load %12 : !llvm.ptr -> i32
// MLIR-NEXT:     %28 = llvm.getelementptr %26[%27] : (!llvm.ptr, i32) -> !llvm.ptr, f64
// MLIR-NEXT:     %29 = llvm.load %28 : !llvm.ptr -> f64
// MLIR-NEXT:     %30 = llvm.fmul %25, %29  : f64
// MLIR-NEXT:     %31 = llvm.load %9 : !llvm.ptr -> f64
// MLIR-NEXT:     %32 = llvm.fadd %31, %30  : f64
// MLIR-NEXT:     llvm.store %32, %9 : f64, !llvm.ptr
// MLIR-NEXT:     llvm.br ^bb4
// MLIR-NEXT:   ^bb4:  // pred: ^bb3
// MLIR-NEXT:     %33 = llvm.load %12 : !llvm.ptr -> i32
// MLIR-NEXT:     %34 = llvm.mlir.constant(1 : i32) : i32
// MLIR-NEXT:     %35 = llvm.add %33, %34  : i32
// MLIR-NEXT:     llvm.store %35, %12 : i32, !llvm.ptr
// MLIR-NEXT:     llvm.br ^bb2
// MLIR-NEXT:   ^bb5:  // pred: ^bb2
// MLIR-NEXT:     llvm.br ^bb6
// MLIR-NEXT:   ^bb6:  // pred: ^bb5
// MLIR-NEXT:     %36 = llvm.load %9 : !llvm.ptr -> f64
// MLIR-NEXT:     llvm.store %36, %7 : f64, !llvm.ptr
// MLIR-NEXT:     %37 = llvm.load %7 : !llvm.ptr -> f64
// MLIR-NEXT:     llvm.return %37 : f64
// MLIR-NEXT:   }
// MLIR-NEXT: }
