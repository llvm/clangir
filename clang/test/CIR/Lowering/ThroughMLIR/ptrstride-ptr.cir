// RUN: cir-opt %s --cir-to-mlir | FileCheck %s -check-prefix=MLIR

!s32i = !cir.int<s, 32>
module {
  cir.func @raw_pointer(%p : !cir.ptr<!s32i>) -> !s32i {
    // MLIR: %[[TWO:.*]] = arith.constant 2 : i32
    // MLIR-NEXT: %[[TYPEOFFSET:.*]] = ptr.type_offset i32 : index
    // MLIR-NEXT: %[[I:.*]] = arith.index_cast %[[TWO]] : i32 to index
    // MLIR-NEXT: %[[OFFSET:.*]] = arith.muli %[[I]], %[[TYPEOFFSET]] : index
    // MLIR-NEXT: %[[CAST1:.*]] = memref.memory_space_cast %arg0 : memref<i32> to memref<i32, #ptr.generic_space>
    // MLIR-NEXT: %[[META:.*]] = ptr.get_metadata %[[CAST1]] : memref<i32, #ptr.generic_space>
    // MLIR-NEXT: %[[P1:.*]] = ptr.to_ptr %[[CAST1]] : memref<i32, #ptr.generic_space> -> <#ptr.generic_space>
    // MLIR-NEXT: %[[P2:.*]] = ptr.ptr_add %[[P1]], %[[OFFSET]] : !ptr.ptr<#ptr.generic_space>, index
    // MLIR-NEXT: %[[PP:.*]] = ptr.from_ptr %[[P2]] metadata %[[META]] : <#ptr.generic_space> -> memref<i32, #ptr.generic_space>
    // MLIR-NEXT: %[[CAST2:.*]] = memref.memory_space_cast %[[PP]] : memref<i32, #ptr.generic_space> to memref<i32>
    // MLIR-NEXT: %[[R:.*]] = memref.load %[[CAST2]][] : memref<i32>
    // MLIR-NEXT: return %[[R]] : i32

    %0 = cir.const #cir.int<2> : !s32i
    %1 = cir.ptr_stride %p, %0 : (!cir.ptr<!s32i>, !s32i) -> !cir.ptr<!s32i>
    %2 = cir.load %1 : !cir.ptr<!s32i>, !s32i
    cir.return %2 : !s32i
  }

  cir.func @raw_complex_pointer(%p : !cir.ptr<!cir.array<!s32i x 8>>) -> !s32i {
    // MLIR: %[[C2_I32:.*]] = arith.constant 2 : i32
    // MLIR-NEXT: %[[INNER_OFFSET:.*]] = ptr.type_offset i32 : index
    // MLIR-NEXT: %[[C2_INDEX:.*]] = arith.index_cast %[[C2_I32]] : i32 to index
    // MLIR-NEXT: %[[MUL1:.*]] = arith.muli %[[C2_INDEX]], %[[INNER_OFFSET]] : index
    // MLIR-NEXT: %[[C8:.*]] = arith.constant 8 : index
    // MLIR-NEXT: %[[MUL2:.*]] = arith.muli %[[MUL1]], %[[C8]] : index
    // MLIR-NEXT: %[[CAST1:.*]] = memref.memory_space_cast %arg0 : memref<8xi32> to memref<8xi32, #ptr.generic_space>
    // MLIR-NEXT: %[[META:.*]] = ptr.get_metadata %[[CAST1]] : memref<8xi32, #ptr.generic_space>
    // MLIR-NEXT: %[[P1:.*]] = ptr.to_ptr %[[CAST1]] : memref<8xi32, #ptr.generic_space> -> <#ptr.generic_space>
    // MLIR-NEXT: %[[P2:.*]] = ptr.ptr_add %[[P1]], %[[MUL2]] : !ptr.ptr<#ptr.generic_space>, index
    // MLIR-NEXT: %[[PP:.*]] = ptr.from_ptr %[[P2]] metadata %[[META]] : <#ptr.generic_space> -> memref<8xi32, #ptr.generic_space>
    // MLIR-NEXT: %[[CAST2:.*]] = memref.memory_space_cast %[[PP]] : memref<8xi32, #ptr.generic_space> to memref<8xi32>
    // MLIR-NEXT: %[[I2:.*]] = arith.index_cast %[[C2_I32]] : i32 to index
    // MLIR-NEXT: %[[R:.*]] = memref.load %[[CAST2]][%[[I2]]] : memref<8xi32>
    // MLIR-NEXT: return %[[R]] : i32
    %0 = cir.const #cir.int<2> : !s32i
    %1 = cir.ptr_stride %p, %0 : (!cir.ptr<!cir.array<!s32i x 8>>, !s32i) -> !cir.ptr<!cir.array<!s32i x 8>>
    %2 = cir.get_element %1[%0] : (!cir.ptr<!cir.array<!s32i x 8>>, !s32i) -> !cir.ptr<!s32i>
    %3 = cir.load %2 : !cir.ptr<!s32i>, !s32i
    cir.return %3 : !s32i
  }
}
