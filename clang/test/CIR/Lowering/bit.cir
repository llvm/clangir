// RUN: cir-opt %s -cir-to-llvm -o %t.mlir
// RUN: FileCheck %s --input-file=%t.mlir

!s16i = !cir.int<s, 16>
!s32i = !cir.int<s, 32>
!s64i = !cir.int<s, 64>
!u16i = !cir.int<u, 16>
!u32i = !cir.int<u, 32>
!u64i = !cir.int<u, 64>

cir.func @clrsb_s32(%arg : !s32i) {
  %0 = cir.bit.clrsb(%arg : !s32i) : !s32i
  cir.return
}

//      CHECK: llvm.func @clrsb_s32(%arg0: i32)
// CHECK-NEXT:   %0 = llvm.mlir.constant(0 : i32) : i32
// CHECK-NEXT:   %1 = llvm.icmp "slt" %arg0, %0 : i32
// CHECK-NEXT:   %2 = llvm.mlir.constant(-1 : i32) : i32
// CHECK-NEXT:   %3 = llvm.xor %arg0, %2  : i32
// CHECK-NEXT:   %4 = llvm.select %1, %3, %arg0 : i1, i32
// CHECK-NEXT:   %5 = "llvm.intr.ctlz"(%4) <{is_zero_poison = false}> : (i32) -> i32
// CHECK-NEXT:   %6 = llvm.mlir.constant(1 : i32) : i32
// CHECK-NEXT:   %7 = llvm.sub %5, %6 : i32
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @clrsb_s64(%arg : !s64i) {
  %0 = cir.bit.clrsb(%arg : !s64i) : !s64i
  cir.return
}

//      CHECK: llvm.func @clrsb_s64(%arg0: i64)
// CHECK-NEXT:   %0 = llvm.mlir.constant(0 : i64) : i64
// CHECK-NEXT:   %1 = llvm.icmp "slt" %arg0, %0 : i64
// CHECK-NEXT:   %2 = llvm.mlir.constant(-1 : i64) : i64
// CHECK-NEXT:   %3 = llvm.xor %arg0, %2  : i64
// CHECK-NEXT:   %4 = llvm.select %1, %3, %arg0 : i1, i64
// CHECK-NEXT:   %5 = "llvm.intr.ctlz"(%4) <{is_zero_poison = false}> : (i64) -> i64
// CHECK-NEXT:   %6 = llvm.mlir.constant(1 : i64) : i64
// CHECK-NEXT:   %7 = llvm.sub %5, %6 : i64
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @clz_u16(%arg : !u16i) {
  %0 = cir.bit.clz(%arg : !u16i) zero_poison : !u16i
  cir.return
}

//      CHECK: llvm.func @clz_u16(%arg0: i16)
// CHECK-NEXT:   %0 = "llvm.intr.ctlz"(%arg0) <{is_zero_poison = true}> : (i16) -> i16
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @clz_u32(%arg : !u32i) {
  %0 = cir.bit.clz(%arg : !u32i) : !u32i
  cir.return
}

//      CHECK: llvm.func @clz_u32(%arg0: i32)
// CHECK-NEXT:   %0 = "llvm.intr.ctlz"(%arg0) <{is_zero_poison = false}> : (i32) -> i32
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @clz_u64(%arg : !u64i) {
  %0 = cir.bit.clz(%arg : !u64i) zero_poison : !u64i
  cir.return
}

//      CHECK: llvm.func @clz_u64(%arg0: i64)
// CHECK-NEXT:   %0 = "llvm.intr.ctlz"(%arg0) <{is_zero_poison = true}> : (i64) -> i64
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @ctz_u16(%arg : !u16i) {
  %0 = cir.bit.ctz(%arg : !u16i) : !u16i
  cir.return
}

//      CHECK: llvm.func @ctz_u16(%arg0: i16)
// CHECK-NEXT:   %0 = "llvm.intr.cttz"(%arg0) <{is_zero_poison = false}> : (i16) -> i16
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @ctz_u32(%arg : !u32i) {
  %0 = cir.bit.ctz(%arg : !u32i) zero_poison : !u32i
  cir.return
}

//      CHECK: llvm.func @ctz_u32(%arg0: i32)
// CHECK-NEXT:   %0 = "llvm.intr.cttz"(%arg0) <{is_zero_poison = true}> : (i32) -> i32
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @ctz_u64(%arg : !u64i) {
  %0 = cir.bit.ctz(%arg : !u64i) : !u64i
  cir.return
}

//      CHECK: llvm.func @ctz_u64(%arg0: i64)
// CHECK-NEXT:   %0 = "llvm.intr.cttz"(%arg0) <{is_zero_poison = false}> : (i64) -> i64
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @ffs_s32(%arg : !s32i) {
  %0 = cir.bit.ffs(%arg : !s32i) : !s32i
  cir.return
}

//      CHECK: llvm.func @ffs_s32(%arg0: i32)
// CHECK-NEXT:   %0 = "llvm.intr.cttz"(%arg0) <{is_zero_poison = false}> : (i32) -> i32
// CHECK-NEXT:   %1 = llvm.mlir.constant(1 : i32) : i32
// CHECK-NEXT:   %2 = llvm.add %0, %1  : i32
// CHECK-NEXT:   %3 = llvm.mlir.constant(0 : i32) : i32
// CHECK-NEXT:   %4 = llvm.icmp "eq" %arg0, %3 : i32
// CHECK-NEXT:   %5 = llvm.mlir.constant(0 : i32) : i32
// CHECK-NEXT:   %6 = llvm.select %4, %5, %2 : i1, i32
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @ffs_s64(%arg : !s64i) {
  %0 = cir.bit.ffs(%arg : !s64i) : !s64i
  cir.return
}

//      CHECK: llvm.func @ffs_s64(%arg0: i64)
// CHECK-NEXT:   %0 = "llvm.intr.cttz"(%arg0) <{is_zero_poison = false}> : (i64) -> i64
// CHECK-NEXT:   %1 = llvm.mlir.constant(1 : i64) : i64
// CHECK-NEXT:   %2 = llvm.add %0, %1  : i64
// CHECK-NEXT:   %3 = llvm.mlir.constant(0 : i64) : i64
// CHECK-NEXT:   %4 = llvm.icmp "eq" %arg0, %3 : i64
// CHECK-NEXT:   %5 = llvm.mlir.constant(0 : i64) : i64
// CHECK-NEXT:   %6 = llvm.select %4, %5, %2 : i1, i64
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @parity_s32(%arg : !u32i) {
  %0 = cir.bit.parity(%arg : !u32i) : !u32i
  cir.return
}

//      CHECK: llvm.func @parity_s32(%arg0: i32)
// CHECK-NEXT:   %0 = llvm.intr.ctpop(%arg0) : (i32) -> i32
// CHECK-NEXT:   %1 = llvm.mlir.constant(1 : i32) : i32
// CHECK-NEXT:   %2 = llvm.and %0, %1  : i32
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @parity_s64(%arg : !u64i) {
  %0 = cir.bit.parity(%arg : !u64i) : !u64i
  cir.return
}

//      CHECK: llvm.func @parity_s64(%arg0: i64)
// CHECK-NEXT:   %0 = llvm.intr.ctpop(%arg0) : (i64) -> i64
// CHECK-NEXT:   %1 = llvm.mlir.constant(1 : i64) : i64
// CHECK-NEXT:   %2 = llvm.and %0, %1 : i64
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @popcount_u16(%arg : !u16i) {
  %0 = cir.bit.popcount(%arg : !u16i) : !u16i
  cir.return
}

//      CHECK: llvm.func @popcount_u16(%arg0: i16)
// CHECK-NEXT:   %0 = llvm.intr.ctpop(%arg0) : (i16) -> i16
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @popcount_u32(%arg : !u32i) {
  %0 = cir.bit.popcount(%arg : !u32i) : !u32i
  cir.return
}

//      CHECK: llvm.func @popcount_u32(%arg0: i32)
// CHECK-NEXT:   %0 = llvm.intr.ctpop(%arg0) : (i32) -> i32
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }

cir.func @popcount_u64(%arg : !u64i) {
  %0 = cir.bit.popcount(%arg : !u64i) : !u64i
  cir.return
}

//      CHECK: llvm.func @popcount_u64(%arg0: i64)
// CHECK-NEXT:   %0 = llvm.intr.ctpop(%arg0) : (i64) -> i64
// CHECK-NEXT:   llvm.return
// CHECK-NEXT: }
